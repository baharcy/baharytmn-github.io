<!DOCTYPE HTML>
<!--
	Solid State by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Machine learning</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
					<header id="header">
						<h1><a href="index.html">HOME</a></h1>
						<nav>
							<a href="#menu">Modules</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<div class="inner">
							<h2>MSc data science</h2>
							<ul class="links">
								<li><a href="index.html">Home</a></li>
								<li><a href="DBD.html">DECIPHERING BIG DATA</a></li>
								<li><a href="VD.html">VISUALISING DATA</a></li>
								<li><a href="NA.html">NUMERICAL ANALYSIS</a></li>
							
							</ul>
							<a href="#" class="close">Close</a>
						</div>
					</nav>

				<!-- Wrapper -->
					<section id="wrapper">
						<header>
							<div class="inner">
								<h2>MACHINE LEARNING</h2>
								<p>Demonstration of Projects, Reflections, and Other Artefacts: My Journey in Machine Learning.</p>
							</div>
						</header>
                                                          <!-- Content -->
							<div class="wrapper">
								<div class="inner">

									<h3 class="major">Unit 1 Collaborative Discussion I: The 4th Industrial Revolution</h3>
									<p> <h3>Initial Post</h3></p>
									<p>
										The Fourth Industrial Revolution (4IR) has profoundly transformed various industries, including finance, by integrating physical, digital, and biological realms through technologies such as AI, robotics, and blockchain (Salesforce, 2023). This transformation offers significant benefits, such as increased productivity, enhanced customer experiences, and personalised products and services. However, it also presents considerable challenges, particularly regarding cybersecurity (Global Banking and Finance, N.D.).
										
										Digital transformation initiatives in financial institutions have made it easier for cybercriminals to access highly sensitive data. A notable example is the 2017 Equifax data breach, which exposed sensitive information of about 147 million individuals (nearly 40% of the U.S. population), including identity details, social security numbers, and credit card information. The consequences were severe; affected customers faced increased risk of identity theft and fraud, resorting to measures like credit freezes and close financial monitoring. The breach also caused significant emotional distress and anxiety. For Equifax, the economic impact included a $700 million settlement, along with substantial reputational damage, eroding consumer trust and market position (Upguard, 2024; Wikipedia, 2024). The Equifax breach highlights the critical need for robust cybersecurity measures in line with the rapid advancements of 4IR technologies. Therefore, financial institutions must invest significantly in securing sensitive data to mitigate the risks associated with digital transformation.
										
										In summary, as Schwab (2016) notes, while 4IR brings numerous advantages, it also necessitates a balanced approach to innovation and security to manage the associated risks effectively.
										
										 
										
										
										
										</p>References: 
										
										</p>GlobalBankingandFinance (no date) The Fourth Industrial Revolution & the Impact on Banking & Finance (Challenges & Opportunities), globalbankingandfinance. Available at: https://www.globalbankingandfinance.com/the-fourth-industrial-revolution-the-impact-on-banking-finance-challenges-opportunities/ [Accessed: 04 August 2024]. 
										
										</p>Salesforce (2023) What is the Fourth Industrial Revolution?, Salesforce. Available at: https://www.salesforce.com/blog/what-is-the-fourth-industrial-revolution-4ir/ [Accessed: 03 August 2024]. 
										
										</p>Schwab, K. (2016) The Fourth Industrial Revolution. World Economic Forum. [Accessed: 03 August 2024]. 
										
										<p>Upguard (2024) 10 biggest data breaches in finance: Upguard, RSS. Available at: https://www.upguard.com/blog/biggest-data-breaches-financial-services [Accessed: 04 August 2024]. 
										
										<p>Wikipedia (2024) 2017 Equifax Data Breach, Wikipedia. Available at: https://en.wikipedia.org/wiki/2017_Equifax_data_breach#:~:text=Private%20records%20of%20147.9%20million,the%20public%20until%20September%202017. [Accessed: 04 August 2024]. </p>

									       
										<h3 class="major">Unit 1 Collaborative Discussion I: The 4th Industrial Revolution</h3>
										<p> <h3>Summary Post</h3></p>
										
										<p>Throughout the discussion regarding the Fourth Industrial Revolution (4IR), major incidents due to information systems failures and their consequences have been highlighted. Additionally, the discussion explored how 4IR is transforming industries by integrating physical, digital, and biological realms through technologies like AI, robotics, IoT, and blockchain (Schwab, 2016).

										In my initial post, I focused on the impact of 4IR on the finance sector, emphasising the cybersecurity challenges that arise from digital transformation. The Equifax data breach in 2017 served as an example, exposing the sensitive information of 147 million individuals and causing significant economic and reputational damage to the company (Upguard, 2024). This incident underscores the critical need for robust cybersecurity measures to accompany the rapid adoption of 4IR technologies.

										My peers contributed valuable insights to the discussion. Tala expanded on the growing need for data storage and management as Big Data continues to expand, particularly for financial institutions handling vast amounts of sensitive information. Aneil introduced the application of blockchain technology beyond finance, particularly in healthcare, highlighting the importance of considering environmental impacts and regulatory frameworks when adopting new technologies. Aminur emphasised the importance of human factors in cybersecurity, noting that human error remains a significant contributor to cyberattacks despite technological advancements.

										The discussion also aligned with the topics covered in Units 1, 2, and 3 of our ML module. Unit 1 introduced the timeline and the future of machine learning, which ties into how 4IR leverages AI and big data analytics to drive innovation. Unit 2 focused on exploratory data analysis (EDA), which is crucial in validating and preparing data for machine learning algorithms and making informed decisions. Lastly, Unit 3 on Correlation and Regression is relevant in understanding the relationships between variables.

										In summary, this discussion reflected the progress of 4IR, pointing out both opportunities and challenges in this transformation, while the three units provide essential knowledge about the key concepts driving this evolution.
										 
										
										
										
										</p>References: 
										
										</p>Schwab, K. (2016) The Fourth Industrial Revolution. World Economic Forum. [Accessed: 03 August 2024].  
										
										</p>Upguard (2024) 10 biggest data breaches in finance: Upguard, RSS. Available at: https://www.upguard.com/blog/biggest-data-breaches-financial-services [Accessed: 04 August 2024].  
									

										<p><h3>Peer Responses</h3></p>
										<p><a href="https://github.com/baharcy/baharytmn-github.io/blob/main/DISCUSSION%201.docx">View my peer responses</a></p>
										 

										
										<<section> <!-- Start of the section -->
                                                                                <article> <!-- Unit 2 Article -->
                                                                                <br><br> <!-- Adds two line breaks -->
                                                                                <h3 class="major">Unit 2 Seminar Preparation - EDA Tutorial</h3>
        									<br><!-- Adds line breaks -->
										<p><a href="https://github.com/baharcy/baharytmn-github.io/blob/main/UNIT%202%20EDA%20TUTORIAL.ipynb">View Python Code for Unit 2 Tutorial</a></p>
      										
										<p>In this tutorial, I conducted exploratory data analysis (EDA) on the Auto-mpg dataset, revealing that larger, heavier, and more powerful cars are less fuel-efficient (MPG), with positive correlations among these variables. Most variables showed positive skewness, indicating long right tails, while negative kurtosis suggested flatter distributions.</p>



   										</article>

    										<article> <!-- Unit 3 Article -->
        									<br><!-- Adds line breaks -->
        									<h3 class="major">Unit 3 Correlation and Regression</h3>
       									        <a href="https://github.com/baharcy/baharytmn-github.io/blob/main/Unit03%20COMPONENT%20Ex%201%20covariance_pearson_correlation.ipynb">View Python Code for Unit03 COMPONENT Covariance Pearson Correlation</a>
       							                        <br><br> <!-- Adds two line breaks -->
										<p><a href="https://github.com/baharcy/baharytmn-github.io/blob/main/Unit03%20COMPONENT%20Ex2%20linear_regression.ipynb">View Python Code for Unit03 COMPONENT Linear Regression</a></p>
        									<p><a href="https://github.com/baharcy/baharytmn-github.io/blob/main/Unit03%20COMPONENT%20Ex3%20multiple_linear_regression.ipynb">View Python Code for Unit03 COMPONENT Multiple Linear Regression</a></p>
     										<p><a href="https://github.com/baharcy/baharytmn-github.io/blob/main/Unit03%20COMPONENT%20Ex4%20polynomial_regression.ipynb">View Python Code for Unit03 COMPONENT Polynomial Regression</a></p>
        									<p>In this activity, I ran programs on covariance, Pearson correlation, linear regression, multiple linear regression, and polynomial regression. In the first example, by adjusting variables, I observed that changing the standard deviation affects covariance, with higher variability reducing it, but it does not impact Pearson correlation since it measures the strength of the linear relationship independent of scale. Additionally, changes in the mean have no effect on either covariance or Pearson correlation, as both are based on deviations from the mean. In the second example, the linear regression model’s predictions and correlation can shift significantly when new data points, especially extreme values, are added to the dataset. The third example demonstrates a positive relationship between a car's weight and engine volume with CO2 emissions using a multiple linear regression model. In the last example, we used polynomial regression since the relationship between the independent variable (time) and the dependent variable (speed) is nonlinear.</p>
    										</article>
										</section> <!-- End of the section -->


        									<h3 class="major">Unit 4 Seminar Preparation - Linear Regression with Scikit-Learn</h3>
       									        <p><a href="https://github.com/baharcy/baharytmn-github.io/blob/main/UNIT%204%20Seminar%20Linear%20Regression%20with%20Scikit-Learn.ipynb">View Python Code for Unit04 Linear Regression with Scikit-Learn</a></p>
								    
									        <p>In this analysis, I used data from Global_Population.csv and Global_GDP.csv to explore the relationship between average population and per capita GDP across countries from 2001 to 2021. The results reveal a moderately positive correlation (0.712) and an R² of 0.506, indicating that the model explains 50.6% of the variance in GDP. However, the high mean squared error (MSE) suggests significant prediction errors, which may be due to missing explanatory variables.</p>

											
										<h3 class="major">Unit 5 Jaccard Coefficient Calculations</h3>
										<p><a href="https://github.com/baharcy/baharytmn-github.io/blob/main/Jaccard.pdf">View Solution for Unit05 Jaccard Coefficient Calculations</a></p>	
											
										<h3 class="major">Unit 5 Wiki Activity: Clustering</h3>
						                                <p>	
											
										The K-means clustering activity demonstrates the iterative nature of the algorithm, where data points are assigned to the nearest centroid, and these centroids are subsequently updated until convergence is achieved. This process illustrates how the initial placement of centroids significantly influences the final clustering results. A poor choice of starting points can lead to suboptimal clustering outcomes, underscoring the importance of careful initialisation in achieving effective clustering.	

										<h3 class="major">Unit 6 Seminar Preparation</h3>
						                                <p><a href="https://github.com/baharcy/baharytmn-github.io/blob/main/Unit%206%20K-Means%20Clustering%20Iris%20Dataset.ipynb">View Solution for Unit06 K-Means Clustering Irıs Dataset</a></p>	
										<p><a href="https://github.com/baharcy/baharytmn-github.io/blob/main/Unit%206%20K-Means%20Clustering%20Wine%20Dataset.ipynb">View Solution for Unit06 K-Means Clustering Wine Dataset</a></p>	

										<p>In this activity, I developed K-Means clustering models for both the Iris and Wine datasets using k = 3. Overall, K-Means performed reasonably well in both datasets, demonstrating clear success in distinguishing the more easily separable classes, such as Iris-setosa and Class 1 of the Wine dataset. However, the algorithm encountered challenges in accurately clustering instances from classes with overlapping features, notably Iris-versicolour and Iris-virginica, as well as between Class 2 and Class 3 in the Wine dataset. These results highlight the limitations of K-Means clustering in scenarios where the feature distributions of different classes are not well-separated.</p>
										
										<h3 class="major">Unit 7 Perceptron Activities</h3>
										<p>
										In a simple perceptron example, the sum function and the step function were utilized. The step function represents the simplest form of an activation function (GeeksforGeeks, 2024). This function determines whether a neuron is activated based on a specified threshold. I experimented with both positive and negative weights. When using positive weights, the resulting values exceeded 1, leading to the activation of the neuron. In contrast, when negative weights were applied, the output values were less than 1, resulting in the neuron remaining inactive.
										Single-layer perceptron can only solve linearly separable problems. However, the XOR problem is not linearly separable. Therefore, we use multi-layer architectures by incorporating hidden layers (GeeksforGeeks, 2024).
										In the perceptron AND operator example, the training process uses a step activation function to solve the XOR problem. It provides an illustration of basic ideas, including weight initialisation, error computation, and weight change during training.
										In the multilayer perceptron example, as an activation function, the sigmoid function is employed, where it ranges values from 0 to 1 to solve the XOR problem. It is aiming to show error computation and backpropagation for weight adjustment and training over multiple epochs to minimise the output error.

										
										 
										
										
										
										</p>References: 
										
										</p>GeeksforGeeks (2024). Activation functions. https://www.geeksforgeeks.org/activation-functions/ [Accessed: 16 October 2024].
										
										</p>GeeksforGeeks (2024) How neural networks solve the XOR problem, GeeksforGeeks. Available at: https://www.geeksforgeeks.org/how-neural-networks-solve-the-xor-problem/ [Accessed: 16 October 2024].</p>
											

										<h3 class="major">Unit 8 Gradient Cost Function</h3>	
						                                <p>In the gradient cost function activity, I explored two crucial parameters: iterations and learning rate. Iterations refer to the number of times the algorithm updates its parameters based on the training data, while the learning rate determines the magnitude of the weight adjustments during each update in the training process. I discovered that increasing iterations generally leads to a reduction in the cost function; however, a high learning rate can produce meaningless outputs. Therefore, balancing these factors is essential for optimising performance and ensuring accurate results in machine learning algorithms.</p>	



										<h3 class="major">Unit 8 Collaborative Discussion II: Legal and Ethical views on ANN applications</h3>
									        <p> <h3>Initial Post</h3></p>
									        <p>
										In recent years, the rise of AI writers, particularly AI chatbots, has led to significant breakthroughs in automated content generation. These AI writers assist with a wide range of tasks, including both administrative and creative writing. Their advantages include increased efficiency, cost savings, and improved comprehension levels, making them appealing to many organisations.
										However, while AI writers offer several advantages, they also raise serious ethical concerns that must be addressed. Critics have described AI writers as “stochastic parrots,” reflecting concerns that this technology may contribute to a less creative work environment (Hutson, 2021; Algolia, 2024).
										In the realm of scientific writing, AI chatbots play an essential role in assisting researchers by organising information, generating initial documents, and proofreading. Nevertheless, the risk of inaccuracies and plagiarism persists, which can have serious implications for research integrity. Moreover, as these tools may transition to paid services, disparities in access could widen the gap between wealthier and poorer nations (Salvagno et al., 2023). In education, while AI writing tools can enhance the learning experience by generating personalised materials and helping students structure their writing, over-reliance on these systems may impede the development of critical thinking and writing skills (Shidiq, 2023).
										Other sectors significantly impacted by AI writing technology include media and entertainment, advertising, healthcare, and finance. While these sectors benefit from increased innovation, they must also address the ethical challenges associated with AI adoption (Nas, 2023).
										In summary, AI writers serve as a double-edged sword; while they enhance productivity and creativity, they also pose risks that require careful consideration and regulatory frameworks.

										
										 
										
										
										
										</p>References: 
										
										</p>Algolia. (2024). AI language models: The good, the bad, and the ugly. https://www.algolia.com/blog/ai/the-pros-and-cons-of-ai-language-models/ [Accessed: 05 October 2024]. 
										
										</p>Hutson, M. (2021). Robo-writers: The rise and risks of language-generating AI. Nature News. https://www.nature.com/articles/d41586-021-00530-0 [Accessed: 05 October 2024]. 
										
										</p>Nas, D. (2023). 5 sectors that will be most affected by Generative AI. Medium. https://deborahnas.medium.com/5-sectors-that-will-be-most-affected-by-generative-ai-fd4c23bc3b0 [Accessed: 05 October 2024].
										
										</p>Salvagno, M., Taccone, F. S., & Gerli, A. G. (2023). Can artificial intelligence help for scientific writing? Critical Care, 27(1), 75 [Accessed: 04 October 2024].
										
										</p>Shidiq, M. (2023). The use of artificial intelligence-based ChatGPT and its challenges for the world of education; from the viewpoint of the development of creative writing skills. In Proceeding of International Conference on Education, Society, and Humanity (Vol. 1, No. 1, pp. 353-357) [Accessed: 05 October 2024].</p>
	
											
										<h3 class="major">Unit 9 CNN Model Activity</h3>
									        <P>
										Wall (2019) highlights the racial bias present in facial recognition technology, raising significant ethical concerns. Yao (2024) supports this perspective by demonstrating that facial recognition systems exhibit higher error rates for minorities, which can lead to unfair treatment. Yao addresses privacy concerns associated with advanced deep learning technologies, particularly the potential for unauthorised tracking in public spaces, which cause violations of individuals' rights to privacy. These ethical considerations must be prioritised in the development and application of CNN technology in facial recognition.
										In reviewing the CNN code, I observed the importing of the CIFAR-10 dataset and the necessary data pre-processing steps, including normalisation of pixel values and categorical encoding to prepare the data for training. Another crucial step is creating a validation set to assess the model's performance effectively. The CNN model is then built, with the early stopping callback feature added to prevent overfitting. After completing the evaluation process, I changed the input image and successfully obtained the output “cat.”

										
										
										</p>References: 
										
										</p>BBC News. (2019, July 8). Biased and wrong? Facial Recognition Tech in the dock. https://www.bbc.com/news/business-48842750 [Accessed: 16 October 2024].
										
										</p>Yao, Y. (2024). The Impact of Deep Learning on Computer Vision: From Image Classification to Scene Understanding. Valley International Journal Digital Library, 1428-1433 [Accessed: 16 October 2024].<p>
											
										<h3 class="major">Unit 10 Seminar Preparation - CNN Tutorial</h3>
       									        <p><a href="https://github.com/baharcy/baharytmn-github.io/blob/main/Unit10%20CNN%20Tutorial.ipynb">View Python Code for Unit10 CNN Tutorial</a></p>
								    
									        <p>In this exercise, I explored how convolutional neural networks (CNNs) process images using the pre-trained VGG16 model. VGG16, a popular deep learning architecture for image classification, has been trained on the ImageNet dataset, which contains millions of labelled images. The primary objective was to understand how CNNs progressively extract features from images across different layers. Early layers capture basic patterns like edges and textures, while deeper layers focus on more complex structures and high-level object representations. This investigation provided insights into the hierarchical nature of CNNs and how they transform raw pixels into meaningful features for classification.</p>
	
											
										<h3 class="major">Unit 11 Model Performance Measurement</h3>
       									       
								    
									        <p>The Support Vector Classifier is a supervised learning algorithm used for classification tasks which finds the optimal hyperplane that separates data into distinct classes by maximising the margin between the hyperplane and the closest data points. This approach helps the model generalise well to unseen data (TechTarget, 2023). In this activity, I evaluated the SVC's performance using AUC and R-squared metrics and it can be said increasing the regularisation parameter C led to improved model performance, reflected in higher AUC and R² scores.</p>	
											
											
										</p>TechTarget (2023) What is a support vector machine?: Definition from Whatis, TechTarget. Available at: https://www.techtarget.com/whatis/definition/support-vector-machine-SVM#:~:text=A%20support%20vector%20machine%20(SVM)%20is%20a%20type%20of%20supervised,data%20set%20into%20two%20groups [Accessed: 16 October 2024].</p> 	
											
										
										<h3 class="major">Unit 12 Future of Machine Learning</h3>
											
										<p>According to Diez-Olivan et al. (2019), Industry 4.0 enables the extraction of valuable insights from industrial assets using data fusion and machine learning techniques. The paper categorises data-driven industrial prognosis into three types: descriptive prognosis, which analyses the root causes of failures; predictive prognosis, which forecasts when failures will occur; and prescriptive prognosis, which recommends actions to minimise the impact of failures.
										In the finance sector, predictive prognostic models play a key role in forecasting future market conditions. By leveraging extensive historical data and advanced analytical techniques, these models enable financial institutions to assess and mitigate potential risks. Furthermore, they maximise returns by guiding firms in making informed, data-driven investment decisions (Investopedia,N.D) . Ultimately, predictive models empower organisations to proactively anticipate market changes, gaining a competitive advantage as the sector transforms.</p>


										</p>References: 
											
										</p>Diez-Olivan, A., Del Ser, J., Galar, D., & Sierra, B. (2019). Data fusion and machine learning for industrial prognosis: Trends and perspectives towards Industry 4.0. Information Fusion, 50, 92-111.
											
										</p>Investopedia (no date) What is predictive modeling?, Investopedia. Available at: https://www.investopedia.com/terms/p/predictive-modeling.asp [Accessed: 17 October 2024].<p> 
	
											
											<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
